spring:
  application:
    name: logx-gateway-http
  profiles:
    active: dev

  # Kafka
  kafka:
    bootstrap-servers: localhost:29092
    producer:
      retries: 3
      batch-size: 16384
      buffer-memory: 33554432
      compression-type: lz4
      acks: all
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: logx-gateway-http
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer

  # Elasticsearch
  elasticsearch:
    uris: http://localhost:9200
    username: elastic
    password: UHTmljcPmCXBpyuWW9nv
  # Redis
  data:
    redis:
      host: localhost
      port: 6379
      database: 0
      password: redis123
      lettuce:
        pool:
          max-active: 20
          max-idle: 10
          min-idle: 5
          max-wait: 2000ms
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3307/logx?useUnicode=true&characterEncoding=utf8&zeroDateTimeBehavior=convertToNull&useSSL=true&serverTimezone=GMT%2B8
    username: root
    password: root123

# Mybatis-plus
mybatis-plus:
  mapper-locations: classpath*:mapper/**/*.xml
  type-aliases-package: com.domidodo.**.domain
  configuration:
    # 开启驼峰命名映射
    map-underscore-to-camel-case: true
    # 设置为true，表示对null值也执行setter
    call-setters-on-nulls: true
    # 将日志输出到控制台 不配置的话MyBatis-Plus的日志默认是warn级别
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
  # 逻辑删除
  global-config:
    db-config:
      logic-delete-field: delFlag # 全局逻辑删除的实体字段名(since 3.3.0,配置后可以忽略不配置步骤2)
      logic-delete-value: UNIX_TIMESTAMP() # 逻辑已删除值(默认为 1) 删除时间戳
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)
    banner: false # 关闭打印 MyBatis-Plus 的 LOGO

server:
  port: 10240
  servlet:
    context-path: /

# 日志平台配置
logx:
  # Kafka Topic
  kafka:
    topic:
      log-ingestion: logx-logs
      log-processing: logx-logs-processing

  # 限流配置
  rate-limit:
    enabled: true
    global:
      qps: 10000  # 全局每秒10000个请求
    tenant:
      qps: 1000   # 每个租户每秒1000个请求
    system:
      qpm: 5000   # 每个系统每分钟5000个请求

  # 批量配置
  batch:
    max-size: 100  # 单次最大日志条数

  # API Key 验证
  security:
    api-key-header: X-API-Key
    tenant-id-header: X-Tenant-Id
    system-id-header: X-System-Id

# 日志配置
logging:
  level:
    root: INFO
    com.domidodo.gateway: DEBUG
    org.springframework.kafka: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n"

# 监控端点
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  prometheus:
    metrics:
      export:
        enabled: true